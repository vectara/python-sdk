# This file was auto-generated by Fern from our API Definition.

from ..core.pydantic_utilities import UniversalBaseModel
import typing
import pydantic
from ..core.pydantic_utilities import IS_PYDANTIC_V2


class ModelParameters(UniversalBaseModel):
    """
    The parameters for the model. These are currently a Scale-only feature.
    See https://vectara.com/pricing/ for more details on becoming a Scale customer.
    WARNING: This is an experimental feature, and breakable at any point with virtually no
    notice. It is meant for experimentation to converge on optimal parameters that can then
    be set in the prompt definitions.
    """

    max_tokens: typing.Optional[int] = pydantic.Field(default=None)
    """
    The maximum number of tokens to be returned by the model.
    """

    temperature: typing.Optional[float] = pydantic.Field(default=None)
    """
    The sampling temperature to use. Higher values make the output more random, while lower
    values make it more focused and deterministic.
    """

    frequency_penalty: typing.Optional[float] = pydantic.Field(default=None)
    """
    Higher values penalize new tokens based on their existing frequency in the text so far,
    decreasing the model's likelihood to repeat the same line verbatim.
    """

    presence_penalty: typing.Optional[float] = pydantic.Field(default=None)
    """
    Higher values penalize new tokens based on whether they appear in the text so far,
    increasing the model's likelihood to talk about new topics.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
